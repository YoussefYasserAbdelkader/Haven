Absolutely! Here's a well-structured and professionalâ€¯README.mdâ€¯for your Haven voice therapy assistant project, incorporating all the key features like voice input/output, Claude local model, sentiment-aware responses, and Spotify control:

---

# ğŸ§ Haven â€“ Your Compassionate Voice Therapy Assistant

Haven is a real-time, voice-enabled AI therapy assistant built with LiveKit Agents, local LLMs (Claude-compatible), Whisper for STT, and sentiment-aware conversation. It also supports voice-controlled Spotify integration to provide music therapy as part of the experience.

---

## ğŸ’¡ Features

* ğŸ¤ Real-time voice input using Whisper via LiveKit Agents
* ğŸ§  Local LLM (e.g., Nous Hermes 2) for private, empathetic responses
* ğŸ”ˆ Instant TTS (text-to-speech) responses for streaming therapy replies
* â¤ï¸ Sentiment-aware responses: soothing tone for sadness, gentle celebration for positivity
* ğŸµ Spotify integration: recommend/play/pause music using voice commands
* ğŸ”’ Completely private â€“ runs locally without any OpenAI or cloud dependencies

---

## ğŸ› ï¸ Tech Stack

| Layer         | Technology                                   |
| ------------- | -------------------------------------------- |
| STT           | Whisper via LiveKit Agents                   |
| TTS           | ElevenLabs / local TTS engine                |
| AI Model      | Nous Hermes 2 (Claude-compatible) via Ollama |
| Voice Control | LiveKit Realtime Audio Agents                |
| Frontend      | Vite + React (App.jsx entry point)           |
| Backend       | FastAPI + Python (`api.py`, `agent.py`)      |
| Spotify       | Spotipy SDK (OAuth2 auth + playback control) |

---

## ğŸš€ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/yourname/haven-therapy.git
cd haven-therapy
```

---

### 2. Environment Setup

Create a `.env` file in both the backend and frontend folders.

#### `.env` (backend):

```env
LIVEKIT_URL=wss://your-livekit-url.livekit.cloud
LIVEKIT_API_KEY=your_livekit_api_key
LIVEKIT_API_SECRET=your_livekit_api_secret

LM_API_URL=http://localhost:11434/v1  # Ollama running Nous Hermes 2

SPOTIPY_CLIENT_ID=your_spotify_client_id
SPOTIPY_CLIENT_SECRET=your_spotify_client_secret
SPOTIPY_REDIRECT_URI=http://localhost:8888/callback
```

---

### 3. Run Backend

Install requirements and start the FastAPI server:

```bash
cd haven_backend
pip install -r requirements.txt
uvicorn api:app --host 0.0.0.0 --port 3000
```

To run the LiveKit agent worker:

```bash
python agent.py
```

Ensure your Claude-compatible model (e.g., Nous Hermes 2) is running with Ollama:

```bash
ollama run nous-hermes2
```

---

### 4. Run Frontend

```bash
cd haven_frontend
npm install
npm run dev
```

This should launch the app at `http://localhost:5173`.

---

## ğŸ—£ï¸ How It Works

* Press and hold the ğŸ¤ "Hold to talk" button
* Whisper transcribes your voice and sends it to the LLM
* The LLM generates an emotionally aware response
* The response is converted to voice and streamed back in real time
* If you're feeling down, Haven may recommend a Spotify playlist
* You can also say:

  * â€œPlay \[song name]â€
  * â€œPause musicâ€
  * â€œSkip trackâ€
  * â€œPlay relaxing musicâ€
  * etc.

---

## ğŸ“ Project Structure

```
haven/
â”œâ”€â”€ haven_backend/
â”‚   â”œâ”€â”€ api.py
â”‚   â”œâ”€â”€ agent.py
â”‚   â”œâ”€â”€ prompts.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â”œâ”€â”€ haven_frontend/
â”‚   â”œâ”€â”€ App.jsx
â”‚   â”œâ”€â”€ main.jsx
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ ChatWindow.jsx
â”‚   â”œâ”€â”€ styles/
â”‚   â”‚   â”œâ”€â”€ app.css
â”‚   â”‚   â””â”€â”€ ChatWindow.css
â”‚   â””â”€â”€ .env
```

---

## ğŸ§  Model Notes

We use `nous-hermes2:10.7b` via Ollama for empathetic dialogue. For better speed, you may switch to a smaller Claude-compatible model (e.g., TinyLlama, Mistral) and update the `LM_API_URL`.

---

## ğŸ’¬ Voice Commands for Spotify

| Command                | Action                   |
| ---------------------- | ------------------------ |
| â€œPlay \[song name]â€    | Starts Spotify playback  |
| â€œPause musicâ€          | Pauses playback          |
| â€œResumeâ€ or â€œContinueâ€ | Resumes playback         |
| â€œNextâ€ or â€œSkip trackâ€ | Skips to next track      |
| â€œPlay relaxing musicâ€  | Plays a calming playlist |

---

## ğŸ§ª Troubleshooting

* If voice doesnâ€™t play, check browser permissions for microphone/speaker
* Make sure your Spotify is open and playing on a device
* Use `ollama list` to verify that your model is running
* Keep responses under 10 seconds for optimal TTS streaming

---

## ğŸ“„ License

MIT â€“ use it freely, improve it, and share the calm ğŸ’š

